{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402124fd-7b3d-48ee-b7a6-3c9edbae5119",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "Logistic Classifiers - Part 2\n",
    "\n",
    "Group:\n",
    "* Paola Katherine Pacheco (Facilitator)\n",
    "* Wai Ping Kwok (Evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc0381-6b1d-4d99-a9b9-0ad5b4ef7cf5",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "#### a) [1 mark] Imagine a movie production company wants to use a sentiment analysis model to identify positive/negative reviews of their movies. Which is worse for this use case, a false positive or a false negative, or are they equally bad? What value of β would be suitable for an Fβ score?\n",
    "ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3524b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting turicreate\n",
      "  Downloading turicreate-6.4.1-cp38-cp38-macosx_10_12_intel.macosx_10_12_x86_64.macosx_10_13_intel.macosx_10_13_x86_64.macosx_10_14_intel.macosx_10_14_x86_64.whl (33.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.2/33.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from turicreate) (1.16.0)\n",
      "Collecting coremltools==4.0b3\n",
      "  Downloading coremltools-4.0b3-cp38-none-macosx_10_16_intel.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting prettytable==0.7.2\n",
      "  Downloading prettytable-0.7.2.zip (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas>=0.23.2\n",
      "  Downloading pandas-1.5.3-cp38-cp38-macosx_10_9_x86_64.whl (11.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.24.2-cp38-cp38-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting resampy==0.2.1\n",
      "  Downloading resampy-0.2.1.tar.gz (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow>=2.0.0\n",
      "  Downloading tensorflow-2.11.1-cp38-cp38-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=5.2.0\n",
      "  Downloading Pillow-9.4.0-2-cp38-cp38-macosx_10_10_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting requests>=2.9.1\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.1.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.9 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from turicreate) (5.1.1)\n",
      "Requirement already satisfied: attrs in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from coremltools==4.0b3->turicreate) (22.1.0)\n",
      "Collecting protobuf>=3.1.0\n",
      "  Downloading protobuf-4.22.1-cp37-abi3-macosx_10_9_universal2.whl (397 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.2/397.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting attr\n",
      "  Downloading attr-0.3.2-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numba>=0.32\n",
      "  Downloading numba-0.56.4-cp38-cp38-macosx_10_14_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from pandas>=0.23.2->turicreate) (2.8.2)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from requests>=2.9.1->turicreate) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from requests>=2.9.1->turicreate) (3.4)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate) (23.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate) (4.4.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp38-cp38-macosx_10_10_universal2.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.1.0\n",
      "  Downloading protobuf-3.19.6-cp38-cp38-macosx_10_9_x86_64.whl (980 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.4/980.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp38-cp38-macosx_10_9_x86_64.whl (35 kB)\n",
      "Requirement already satisfied: setuptools in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from tensorflow>=2.0.0->turicreate) (65.6.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-macosx_10_9_x86_64.whl (25.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp38-cp38-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->turicreate) (0.38.4)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp38-cp38-macosx_10_9_x86_64.whl (25.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.5/25.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.23.5-cp38-cp38-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from importlib-metadata->numba>=0.32->resampy==0.2.1->turicreate) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->turicreate) (2.1.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: prettytable, resampy\n",
      "  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13695 sha256=e720990c4f1f974d1932e60fbc32faa2bc71a3000787e412d72fc75a092bdfcc\n",
      "  Stored in directory: /Users/paolakatherine/Library/Caches/pip/wheels/48/6d/77/9517cb933af254f51a446f1a5ec9c2be3e45f17384940bce68\n",
      "  Building wheel for resampy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for resampy: filename=resampy-0.2.1-py3-none-any.whl size=320839 sha256=f02efb13db5a7f3eaa4c2154b4a65c57494c185d234ae6bf00b1ce1bc2ca4821\n",
      "  Stored in directory: /Users/paolakatherine/Library/Caches/pip/wheels/2b/a9/15/89e0e4544c36f50e4e8d54d546f2331c461f505d3b55d3f358\n",
      "Successfully built prettytable resampy\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyasn1, prettytable, mpmath, libclang, flatbuffers, attr, wrapt, werkzeug, urllib3, tqdm, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, sympy, rsa, pyasn1-modules, protobuf, pillow, oauthlib, numpy, llvmlite, keras, importlib-metadata, grpcio, google-pasta, gast, charset-normalizer, cachetools, astunparse, absl-py, scipy, requests, pandas, opt-einsum, numba, markdown, h5py, google-auth, resampy, requests-oauthlib, coremltools, google-auth-oauthlib, tensorboard, tensorflow, turicreate\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 attr-0.3.2 cachetools-5.3.0 charset-normalizer-3.1.0 coremltools-4.0b3 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 h5py-3.8.0 importlib-metadata-6.1.0 keras-2.11.0 libclang-15.0.6.1 llvmlite-0.39.1 markdown-3.4.1 mpmath-1.3.0 numba-0.56.4 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-1.5.3 pillow-9.4.0 prettytable-0.7.2 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytz-2022.7.1 requests-2.28.2 requests-oauthlib-1.3.1 resampy-0.2.1 rsa-4.9 scipy-1.10.1 sympy-1.11.1 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 tqdm-4.65.0 turicreate-6.4.1 urllib3-1.26.15 werkzeug-2.2.3 wrapt-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install turicreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e139e-8302-42a1-8374-25249c2e3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import turicreate as tc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a09d1e-42db-43d5-bfc3-6a45f9302612",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "#### b) [6 marks] Clean the data so that it is better suited for sentiment analysis, according to your ideas in problem 2h. Add a markdown cell to explain what you are doing.\n",
    "#### Choose one of two ways to prepare the data:\n",
    "##### i) Make of copy of the IMBD_Dataset.csv and name it IMBD_Dataset_mod.csv. Open the file in Jupyter Hub and use “find and replace” to clean the text data. OR\n",
    "##### ii) Load the original dataset into a dataframe and use the regex Python library to clean the text data.\n",
    "ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c690cb3-3b35-4356-aca0-0640da2ac1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the original dataset into a pandas dataframe\n",
    "imdb_mod = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "\n",
    "# print the dataframe to take a look\n",
    "imdb_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2697d8-8624-4be0-8dee-050d1b0bcc5b",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "#### c) [2 marks] Load the cleaned data and labels into an SFrame. Add a column named ‘words’ to the SFrame that stores the count of each word used in each review. Print the SFrame.\n",
    "ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866530b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop-words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: stop-words\n",
      "  Building wheel for stop-words (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32895 sha256=d0d94bc853e7d051a4090dc4abfe597a9f45c3b9afc734662a1c400aa084131b\n",
      "  Stored in directory: /Users/paolakatherine/Library/Caches/pip/wheels/eb/03/0d/3bd31c983789aeb0b4d5e2ca48590288d9db1586cf5f225062\n",
      "Successfully built stop-words\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2018.7.23\n"
     ]
    }
   ],
   "source": [
    "! pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a59b582e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstop_words\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_stop_words\n\u001b[1;32m      3\u001b[0m all_stop_words \u001b[38;5;241m=\u001b[39m get_stop_words(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mall_stop_words\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m all_stop_words\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m all_stop_words\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdidn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "all_stop_words = get_stop_words('en')\n",
    "all_stop_words.remove('not')\n",
    "all_stop_words.remove('cannot')\n",
    "all_stop_words.remove('didn\\'t')\n",
    "all_stop_words.append('<br />')\n",
    "\n",
    "print(all_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf397a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imdb_mod)):\n",
    "    text = imdb_mod['review'][i]\n",
    "    filtered = ' '.join([word for word in text.split() if word not in all_stop_words])\n",
    "    imdb_mod['filtered_review'][i] = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b913aac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought movie right good job. It creative or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>I Catholic taught parochial elementary schools...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>I'm going disagree previous comment side Malti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>No one expects Star Trek movies high art, fans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                         filtered_review  \n",
       "49995  I thought movie right good job. It creative or...  \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  \n",
       "49997  I Catholic taught parochial elementary schools...  \n",
       "49998  I'm going disagree previous comment side Malti...  \n",
       "49999  No one expects Star Trek movies high art, fans...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_mod.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a7d0f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">review</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">filtered_review</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">One of the other<br>reviewers has mentioned ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">One reviewers mentioned<br>watching just 1 Oz ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;darker&#x27;: 1.0,<br>&#x27;viewing&#x27;: 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A wonderful little<br>production. &lt;br /&gt;&lt;br ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A wonderful little<br>production. &lt;br /&gt;&lt;br ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;terribly&#x27;: 1.0,<br>&#x27;surface&#x27;: 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">I thought this was a<br>wonderful way to spend ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">I thought wonderful way<br>spend time hot summer ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;see&#x27;: 1.0, &#x27;superman&#x27;:<br>1.0, &#x27;interesting&#x27;: 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Basically there&#x27;s a<br>family where a little ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">negative</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Basically family little<br>boy (Jake) thinks zombie ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;them&#x27;: 1.0, &#x27;ignore&#x27;:<br>1.0, &#x27;dialogs&#x27;: 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Petter Mattei&#x27;s &quot;Love in<br>the Time of Money&quot; is a ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Petter Mattei&#x27;s &quot;Love<br>Time Money&quot; visually ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;work&#x27;: 1.0,<br>&#x27;anxiously&#x27;: 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Probably my all-time<br>favorite movie, a story ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Probably all-time<br>favorite movie, story ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;dozen&#x27;: 1.0, &#x27;i&#x27;: 1.0,<br>&#x27;if&#x27;: 1.0, &#x27;startling&#x27;: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">I sure would like to see<br>a resurrection of a up ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">I sure like see<br>resurrection dated ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;it&#x27;: 1.0, &#x27;doubt&#x27;: 1.0,<br>&#x27;must&#x27;: 1.0, &#x27;leave&#x27;: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">This show was an amazing,<br>fresh &amp; innovative idea ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">negative</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">This show amazing, fresh<br>&amp; innovative idea 70&#x27;s ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;awful&#x27;: 1.0, &#x27;now&#x27;:<br>1.0, &#x27;as&#x27;: 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Encouraged by the<br>positive comments about ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">negative</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Encouraged positive<br>comments film I looking ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;obsessives&#x27;: 1.0,<br>&#x27;effort&#x27;: 1.0, &#x27;bit&#x27;: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">If you like original gut<br>wrenching laughter you ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">positive</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">If like original gut<br>wrenching laughter will ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;br&#x27;: 2.0, &#x27;mom&#x27;: 1.0,<br>&#x27;hell&#x27;: 1.0, &#x27;great&#x27;: ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[50000 rows x 4 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\treview\tstr\n",
       "\tsentiment\tstr\n",
       "\tfiltered_review\tstr\n",
       "\twords\tdict\n",
       "\n",
       "Rows: 50000\n",
       "\n",
       "Data:\n",
       "+-------------------------------+-----------+-------------------------------+\n",
       "|             review            | sentiment |        filtered_review        |\n",
       "+-------------------------------+-----------+-------------------------------+\n",
       "| One of the other reviewers... |  positive | One reviewers mentioned wa... |\n",
       "| A wonderful little product... |  positive | A wonderful little product... |\n",
       "| I thought this was a wonde... |  positive | I thought wonderful way sp... |\n",
       "| Basically there's a family... |  negative | Basically family little bo... |\n",
       "| Petter Mattei's \"Love in t... |  positive | Petter Mattei's \"Love Time... |\n",
       "| Probably my all-time favor... |  positive | Probably all-time favorite... |\n",
       "| I sure would like to see a... |  positive | I sure like see resurrecti... |\n",
       "| This show was an amazing, ... |  negative | This show amazing, fresh &... |\n",
       "| Encouraged by the positive... |  negative | Encouraged positive commen... |\n",
       "| If you like original gut w... |  positive | If like original gut wrenc... |\n",
       "+-------------------------------+-----------+-------------------------------+\n",
       "+-------------------------------+\n",
       "|             words             |\n",
       "+-------------------------------+\n",
       "| {'darker': 1.0, 'viewing':... |\n",
       "| {'terribly': 1.0, 'surface... |\n",
       "| {'see': 1.0, 'superman': 1... |\n",
       "| {'them': 1.0, 'ignore': 1.... |\n",
       "| {'work': 1.0, 'anxiously':... |\n",
       "| {'dozen': 1.0, 'i': 1.0, '... |\n",
       "| {'it': 1.0, 'doubt': 1.0, ... |\n",
       "| {'awful': 1.0, 'now': 1.0,... |\n",
       "| {'obsessives': 1.0, 'effor... |\n",
       "| {'br': 2.0, 'mom': 1.0, 'h... |\n",
       "+-------------------------------+\n",
       "[50000 rows x 4 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert imdb_mod to a SFrame in order to use the count_words \n",
    "df_reviews = tc.SFrame(imdb_mod)\n",
    "df_reviews\n",
    "\n",
    "\n",
    "df_reviews['words'] = tc.text_analytics.count_words(df_reviews['filtered_review'])\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee35a3-03b1-4ca6-9b00-7b4bcfdaeae5",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "#### d) [1 mark] Split the data into training/validation/testing sets using 80%/10%/10% respectively.\n",
    "ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d1a6768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-macosx_10_9_x86_64.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/paolakatherine/opt/anaconda3/envs/python38/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.2.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "31ab27bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid key type: must be str, unicode, bytes or type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 80% \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_data, rest_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_reviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# split rest of data in 50%  ( 10% validation + 10% test)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m validation_data, test_data \u001b[38;5;241m=\u001b[39m train_test_split(rest_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python38/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2585\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m-> 2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2587\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python38/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2587\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2586\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2587\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python38/lib/python3.8/site-packages/sklearn/utils/__init__.py:356\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python38/lib/python3.8/site-packages/sklearn/utils/__init__.py:185\u001b[0m, in \u001b[0;36m_array_indexing\u001b[0;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    184\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python38/lib/python3.8/site-packages/turicreate/data_structures/sframe.py:3828\u001b[0m, in \u001b[0;36mSFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_columns([key])\n\u001b[1;32m   3827\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_non_string_iterable(key):\n\u001b[0;32m-> 3828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3829\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m   3830\u001b[0m     sf_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python38/lib/python3.8/site-packages/turicreate/data_structures/sframe.py:3372\u001b[0m, in \u001b[0;36mSFrame.select_columns\u001b[0;34m(self, column_names)\u001b[0m\n\u001b[1;32m   3361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_names must be an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m   3363\u001b[0m     \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m   3364\u001b[0m         [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3370\u001b[0m     )\n\u001b[1;32m   3371\u001b[0m ):\n\u001b[0;32m-> 3372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key type: must be str, unicode, bytes or type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3374\u001b[0m requested_str_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3375\u001b[0m     s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m column_names \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, six\u001b[38;5;241m.\u001b[39mstring_types)\n\u001b[1;32m   3376\u001b[0m ]\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;66;03m# Make sure there are no duplicates keys\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid key type: must be str, unicode, bytes or type"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80% \n",
    "train_data, rest_data = train_test_split(df_reviews, train_size=0.8)\n",
    "\n",
    "# split rest of data in 50%  ( 10% validation + 10% test)\n",
    "validation_data, test_data = train_test_split(rest_data, test_size=0.5)\n",
    "\n",
    "print(\"Train data length:\", len(train_data))\n",
    "print(\"Validation Data length:\", len(validation_data))\n",
    "print(\"Test Data length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tc.logistic_classifier.create(validation_data, features=['words'], target='sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29cc80-2b60-4951-9dc7-412d22dcf225",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "#### e) [3 marks] Use Turicreate to create logistic classifiers for sentiment analysis. Be sure to use your validation set in the training. Experiment with different values of hyperparameters to develop two different models.\n",
    "ans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f797d0-e3db-4480-a7cc-a434e7a5bae9",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "#### f) [8 marks] For each model:\n",
    "##### i) find predictions using the testing set;\n",
    "##### ii) display the training/validation/testing accuracy;\n",
    "##### iii) display the confusion matrix on the testing set;\n",
    "##### iv) calculate recall, precision, sensitivity and specificity on the testing set;\n",
    "##### v) calculate the Fβ score on the testing set using the value of β you chose above.\n",
    "##### vi) using the testing set, calculate points for and plot the ROC curve (use turicreate.evaluation.roc_curve() and then matplotlib.pyplot());\n",
    "##### vii) calculate the AUC for the testing set.\n",
    "ans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ce777-099a-467f-89b6-905104f58ece",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "#### g) [2 marks] Select which of your two models is the best (or declare a tie) and justify your choice.\n",
    "ans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a33350-6d94-4603-a1bc-a917d21ecab6",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "<table> \n",
    "  <tr>\n",
    "    <th>Student</th>\n",
    "    <th>Paola Katherine Pacheco</th>\n",
    "    <th>Wai Ping Kwok</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Every member contributed</th>\n",
    "    <th>3</th>\n",
    "    <th>3</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Every member treated with respect</th>\n",
    "    <th>3</th>\n",
    "    <th>3</th>\n",
    "  </tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98126474-7527-48b7-a74d-898a39757cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
